<!doctype html>
<html lang="uk">
<head>
  <meta charset="utf-8" />
  <title>AI Voice Agent Test Client</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <style>
    body { font-family: system-ui, -apple-system, Segoe UI, Roboto, sans-serif; margin: 20px; }
    .row { display: flex; gap: 8px; margin: 8px 0; flex-wrap: wrap; }
    input[type="text"] { width: 520px; padding: 8px; }
    button { padding: 8px 12px; }
    .log { border: 1px solid #ccc; padding: 8px; height: 240px; overflow: auto; white-space: pre-wrap; background: #fafafa; font-size: 13px; }
    .small { font-size: 0.9em; color: #666; }
    label { display: inline-flex; align-items: center; gap: 6px; }
    .status { padding: 10px; margin: 10px 0; border-radius: 5px; font-weight: bold; }
    .status-connected { background: #d4edda; color: #155724; }
    .status-listening { background: #d1ecf1; color: #0c5460; }
    .status-disconnected { background: #f8d7da; color: #721c24; }
    .transcripts { margin-top: 20px; padding: 10px; border: 1px solid #ddd; border-radius: 5px; background: #fff; }
    .transcript { padding: 8px; margin: 5px 0; border-radius: 4px; }
    .transcript-user { background: #e3f2fd; text-align: right; }
    .transcript-assistant { background: #f1f8e9; }
    .transcript-label { font-weight: bold; font-size: 11px; margin-bottom: 3px; opacity: 0.7; }
  </style>
</head>
<body>
  <h1>–ì–æ–ª–æ—Å–æ–≤–∏–π –∞–≥–µ–Ω—Ç ‚Äî —Ç–µ—Å—Ç–æ–≤–∏–π –∫–ª—ñ—î–Ω—Ç</h1>

  <div class="row">
    <label>WebSocket URL:
      <input id="wsUrl" type="text" placeholder="wss://YOUR-CLOUD-RUN-URL/audio" />
    </label>
  </div>

  <div class="row">
    <button id="connectBtn">–ü–æ—á–∞—Ç–∏ —Å–µ–∞–Ω—Å</button>
    <button id="disconnectBtn" disabled>–ó–∞–≤–µ—Ä—à–∏—Ç–∏ —Å–µ–∞–Ω—Å</button>
  </div>

  <div id="statusBar" class="status status-disconnected">–ù–µ –ø—ñ–¥–∫–ª—é—á–µ–Ω–æ</div>

  <hr/>

  <div class="row">
    <button id="startMicBtn" disabled>üéôÔ∏è –ü–æ—á–∞—Ç–∏ –º—ñ–∫—Ä–æ—Ñ–æ–Ω</button>
    <button id="stopMicBtn" disabled>‚èπÔ∏è –ó—É–ø–∏–Ω–∏—Ç–∏ –º—ñ–∫—Ä–æ—Ñ–æ–Ω</button>
  </div>

  <div class="row">
    <input id="textInput" type="text" placeholder="–ù–∞–¥—ñ—Å–ª–∞—Ç–∏ —Ç–µ–∫—Å—Ç..." />
    <label><input type="checkbox" id="turnComplete"> turn_complete</label>
    <button id="sendTextBtn" disabled>–ù–∞–¥—ñ—Å–ª–∞—Ç–∏</button>
  </div>

  <p class="small">–ü—Ä–∏–º—ñ—Ç–∫–∞: –∫–ª—ñ—î–Ω—Ç –Ω–∞–¥—Å–∏–ª–∞—î PCM16 mono @ 16kHz —É –¥–≤—ñ–π–∫–æ–≤–∏—Ö —Ñ—Ä–µ–π–º–∞—Ö; –æ—Ç—Ä–∏–º–∞–Ω–µ –∞—É–¥—ñ–æ (PCM16 mono @ 24kHz) –≤—ñ–¥—Ç–≤–æ—Ä—é—î—Ç—å—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ.</p>

  <h3>–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∏</h3>
  <div id="transcripts" class="transcripts"></div>

  <h3>–õ–æ–≥–∏</h3>
  <div id="log" class="log"></div>

<script>
(() => {
  // ---- UI helpers ----
  const $ = (id) => document.getElementById(id);
  const logBox = $("log");
  const statusBar = $("statusBar");
  const transcriptsBox = $("transcripts");
  
  function log(...args) {
    const line = args.map(a => (typeof a === "string" ? a : JSON.stringify(a))).join(" ");
    logBox.textContent += line + "\n";
    logBox.scrollTop = logBox.scrollHeight;
    console.log(...args);
  }

  function setStatus(text, className) {
    statusBar.textContent = text;
    statusBar.className = `status ${className}`;
  }

  function addTranscript(type, text) {
    const div = document.createElement('div');
    div.className = `transcript transcript-${type}`;
    const label = document.createElement('div');
    label.className = 'transcript-label';
    label.textContent = type === 'user' ? '–í–∏:' : '–ê—Å–∏—Å—Ç–µ–Ω—Ç:';
    const content = document.createElement('div');
    content.textContent = text;
    div.appendChild(label);
    div.appendChild(content);
    transcriptsBox.appendChild(div);
    transcriptsBox.scrollTop = transcriptsBox.scrollHeight;
  }

  // ---- State ----
  let ws = null;
  let audioCtx = null;
  let micStream = null;
  let micNode = null;
  let playerNextTime = 0;
  let isModelSpeaking = false;
  let autoStopMicAfterResponse = false;

  const MODEL_SAMPLE_RATE = 24000;
  const SEND_SAMPLE_RATE = 16000;

  // ---- Audio: downsampler worklet ----
  const workletCode = `
    class Downsample16k extends AudioWorkletProcessor {
      constructor() {
        super();
        this._srcRate = sampleRate;
        this._ratio = this._srcRate / 16000;
      }
      static get parameterDescriptors() { return []; }

      process(inputs, outputs, parameters) {
        const input = inputs[0];
        if (!input || input.length === 0) { return true; }
        const ch0 = input[0];
        if (!ch0) return true;

        const inBuf = ch0;
        const ratio = this._ratio;
        const outNeeded = Math.floor(inBuf.length / ratio) + 1;
        const outF32 = new Float32Array(outNeeded);
        let idx = 0;
        for (let i = 0; i < outNeeded; i++) {
          const pos = i * ratio;
          const i0 = Math.floor(pos);
          const i1 = Math.min(i0 + 1, inBuf.length - 1);
          const t = pos - i0;
          const s = (1 - t) * inBuf[i0] + t * inBuf[i1];
          outF32[idx++] = Math.max(-1, Math.min(1, s));
        }

        const outI16 = new Int16Array(outF32.length);
        for (let i = 0; i < outF32.length; i++) {
          outI16[i] = Math.max(-32768, Math.min(32767, Math.floor(outF32[i] * 32767)));
        }

        this.port.postMessage(outI16.buffer, [outI16.buffer]);
        return true;
      }
    }
    registerProcessor('downsample-16k', Downsample16k);
  `;

  async function ensureAudio() {
    if (audioCtx) return;
    audioCtx = new (window.AudioContext || window.webkitAudioContext)();
    const blob = new Blob([workletCode], { type: "application/javascript" });
    const url = URL.createObjectURL(blob);
    await audioCtx.audioWorklet.addModule(url);
    URL.revokeObjectURL(url);
    log("üîä AudioContext —Å—Ç–≤–æ—Ä–µ–Ω–æ @", audioCtx.sampleRate, "Hz");
  }

  // ---- WebSocket connect/disconnect ----
  $("connectBtn").onclick = async () => {
    const url = $("wsUrl").value.trim();
    if (!url || !/^wss?:\/\/.+/.test(url)) {
      alert("–í–∫–∞–∂—ñ—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω–∏–π WebSocket URL (wss://... –∞–±–æ ws://...)");
      return;
    }
    
    try {
      setStatus("–ü—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è...", "status-listening");
      ws = new WebSocket(url);
      ws.binaryType = "arraybuffer";

      ws.onopen = () => {
        log("‚úÖ WebSocket –∑'—î–¥–Ω–∞–Ω–æ");
        setStatus("–ü—ñ–¥–∫–ª—é—á–µ–Ω–æ", "status-connected");
        $("connectBtn").disabled = true;
        $("disconnectBtn").disabled = false;
        $("startMicBtn").disabled = false;
        $("sendTextBtn").disabled = false;
      };

      ws.onmessage = (ev) => {
        if (typeof ev.data === "string") {
          // JSON events
          try {
            const obj = JSON.parse(ev.data);
            log("üì© JSON:", obj);
            handleJsonMessage(obj);
          } catch {
            log("üì© text:", ev.data);
          }
        } else if (ev.data instanceof ArrayBuffer) {
          // Binary model audio
          playPcmChunk(ev.data);
        }
      };

      ws.onerror = (e) => {
        log("‚ùå WS error event:", e);
        setStatus("–ü–æ–º–∏–ª–∫–∞ –∑'—î–¥–Ω–∞–Ω–Ω—è", "status-disconnected");
      };

      ws.onclose = (ev) => {
        log(`‚ÑπÔ∏è WS closed - Code: ${ev.code}, Reason: ${ev.reason || 'none'}, Clean: ${ev.wasClean}`);
        setStatus("–ù–µ –ø—ñ–¥–∫–ª—é—á–µ–Ω–æ", "status-disconnected");
        $("connectBtn").disabled = false;
        $("disconnectBtn").disabled = true;
        $("startMicBtn").disabled = true;
        $("stopMicBtn").disabled = true;
        $("sendTextBtn").disabled = true;
        ws = null;
        stopMic();
      };
    } catch (e) {
      log("‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –ø—ñ–¥–∫–ª—é—á–∏—Ç–∏—Å—è:", e);
      setStatus("–ü–æ–º–∏–ª–∫–∞ –ø—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è", "status-disconnected");
    }
  };

  $("disconnectBtn").onclick = () => {
    if (ws) {
      ws.close(1000, "User closed");
    }
  };

  // ---- Handle JSON messages from server ----
  function handleJsonMessage(obj) {
    switch(obj.type) {
      case "input_transcript":
        addTranscript("user", obj.text);
        log("üë§ –ö–æ—Ä–∏—Å—Ç—É–≤–∞—á —Å–∫–∞–∑–∞–≤:", obj.text);
        break;
      
      case "output_transcript":
        addTranscript("assistant", obj.text);
        log("ü§ñ –ê—Å–∏—Å—Ç–µ–Ω—Ç —Å–∫–∞–∑–∞–≤:", obj.text);
        isModelSpeaking = true;
        setStatus("–ê—Å–∏—Å—Ç–µ–Ω—Ç –≥–æ–≤–æ—Ä–∏—Ç—å...", "status-listening");
        break;
      
      case "turn_complete":
        log("üîÑ Turn complete - ready_for_input:", obj.ready_for_input);
        isModelSpeaking = false;
        
        // –í–ê–ñ–õ–ò–í–û: –í—ñ–¥–ø—Ä–∞–≤–ª—è—î–º–æ –ø–æ—Ä–æ–∂–Ω—ñ–π turn_complete —â–æ–± –º–æ–¥–µ–ª—å –∑–Ω–∞–ª–∞ —â–æ –º–∏ –≥–æ—Ç–æ–≤—ñ
        if (obj.ready_for_input && ws && ws.readyState === WebSocket.OPEN) {
          setTimeout(() => {
            const payload = { turn_complete: true };
            ws.send(JSON.stringify(payload));
            log("‚û°Ô∏è –í—ñ–¥–ø—Ä–∞–≤–ª–µ–Ω–æ turn_complete –¥–ª—è –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç—ñ");
            setStatus("–ì–æ—Ç–æ–≤–∏–π —Å–ª—É—Ö–∞—Ç–∏ (–≥–æ–≤–æ—Ä—ñ—Ç—å –∑–∞—Ä–∞–∑)", "status-connected");
          }, 500); // –Ω–µ–≤–µ–ª–∏–∫–∞ –∑–∞—Ç—Ä–∏–º–∫–∞
        }
        break;
      
      case "interruption":
        log("‚ö†Ô∏è –ü–µ—Ä–µ—Ä–∏–≤–∞–Ω–Ω—è –≤–∏—è–≤–ª–µ–Ω–æ");
        isModelSpeaking = false;
        setStatus("–ü–µ—Ä–µ—Ä–≤–∞–Ω–æ - –≥–æ—Ç–æ–≤–∏–π —Å–ª—É—Ö–∞—Ç–∏", "status-connected");
        break;
      
      case "tool_response_sent":
        log("üîß Tool response sent:", obj.name);
        break;
      
      case "heartbeat":
        // Silent heartbeat - –º–æ–∂–Ω–∞ —Ä–æ–∑–∫–æ–º–µ–Ω—Ç—É–≤–∞—Ç–∏ –¥–ª—è debug
        // log("üíì Heartbeat #" + obj.count);
        break;
      
      case "error":
        log("‚ùå Server error:", obj.message);
        setStatus("–ü–æ–º–∏–ª–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞", "status-disconnected");
        break;
      
      default:
        log("üì¶ Unknown message type:", obj.type);
    }
  }

  // ---- Microphone start/stop ----
  $("startMicBtn").onclick = async () => {
    try {
      await ensureAudio();
      
      // Resume AudioContext if suspended
      if (audioCtx.state === 'suspended') {
        await audioCtx.resume();
      }
      
      micStream = await navigator.mediaDevices.getUserMedia({
        audio: { 
          channelCount: 1, 
          sampleRate: { ideal: 48000 },
          noiseSuppression: true, 
          echoCancellation: true,
          autoGainControl: true
        },
      });
      
      const source = audioCtx.createMediaStreamSource(micStream);
      micNode = new AudioWorkletNode(audioCtx, "downsample-16k");
      
      micNode.port.onmessage = (ev) => {
        if (!ws || ws.readyState !== WebSocket.OPEN) return;
        const buf = ev.data;
        ws.send(buf);
      };
      
      source.connect(micNode);
      
      $("startMicBtn").disabled = true;
      $("stopMicBtn").disabled = false;
      setStatus("–°–ª—É—Ö–∞—é...", "status-listening");
      log("üéôÔ∏è –ú—ñ–∫—Ä–æ—Ñ–æ–Ω –∑–∞–ø—É—â–µ–Ω–æ @", audioCtx.sampleRate, "Hz ‚Üí 16kHz");
    } catch (e) {
      log("‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –æ—Ç—Ä–∏–º–∞—Ç–∏ –¥–æ—Å—Ç—É–ø –¥–æ –º—ñ–∫—Ä–æ—Ñ–æ–Ω–∞:", e);
      alert("–ü–æ–º–∏–ª–∫–∞ –¥–æ—Å—Ç—É–ø—É –¥–æ –º—ñ–∫—Ä–æ—Ñ–æ–Ω–∞: " + e.message);
    }
  };

  $("stopMicBtn").onclick = () => stopMic();

  function stopMic() {
    if (micNode) { 
      try { 
        micNode.port.onmessage = null;
        micNode.disconnect(); 
      } catch(e) { 
        log("Warning disconnecting micNode:", e); 
      } 
      micNode = null; 
    }
    if (micStream) {
      micStream.getTracks().forEach(t => t.stop());
      micStream = null;
    }
    $("startMicBtn").disabled = !ws || ws.readyState !== WebSocket.OPEN;
    $("stopMicBtn").disabled = true;
    
    if (ws && ws.readyState === WebSocket.OPEN) {
      setStatus("–ü—ñ–¥–∫–ª—é—á–µ–Ω–æ", "status-connected");
    }
    log("‚èπÔ∏è –ú—ñ–∫—Ä–æ—Ñ–æ–Ω –∑—É–ø–∏–Ω–µ–Ω–æ");
  }

  // ---- Send text turns ----
  $("sendTextBtn").onclick = () => {
    const text = $("textInput").value.trim();
    const turnComplete = $("turnComplete").checked;
    if (!ws || ws.readyState !== WebSocket.OPEN) return;
    
    const payload = {};
    if (text) payload.text = text;
    if (turnComplete) payload.turn_complete = true;
    
    // Don't send empty payload
    if (!text && !turnComplete) return;
    
    ws.send(JSON.stringify(payload));
    log("‚û°Ô∏è –ù–∞–¥—ñ—Å–ª–∞–Ω–æ:", payload);
    
    if (text) {
      addTranscript("user", text);
    }
    
    $("textInput").value = "";
    $("turnComplete").checked = false;
  };

  // Allow Enter key to send
  $("textInput").addEventListener("keypress", (e) => {
    if (e.key === "Enter") {
      $("sendTextBtn").click();
    }
  });

  // ---- Playback: queue PCM16 @ 24kHz ----

    async function playPcmChunk(arrayBuffer) {
    try {
      await ensureAudio();
      
      // Resume AudioContext if suspended (browser autoplay policy)
      if (audioCtx.state === 'suspended') {
        await audioCtx.resume();
      }
      
      const i16 = new Int16Array(arrayBuffer);
      const length = i16.length;
      
      if (length === 0) return;
      
      const audioBuffer = audioCtx.createBuffer(1, length, MODEL_SAMPLE_RATE);
      const ch = audioBuffer.getChannelData(0);
      
      for (let i = 0; i < length; i++) {
        ch[i] = Math.max(-1, Math.min(1, i16[i] / 32767));
      }

      const src = audioCtx.createBufferSource();
      src.buffer = audioBuffer;

      // Smooth scheduling to avoid clicks/gaps
      const now = audioCtx.currentTime;
      if (playerNextTime < now) {
        playerNextTime = now + 0.02; // small headroom
      }
      
      src.connect(audioCtx.destination);
      src.start(playerNextTime);
      playerNextTime += audioBuffer.duration;
      
      // Optional: log first audio chunk
      if (!isModelSpeaking) {
        log("üîä –ü–æ—á–∏–Ω–∞—é –≤—ñ–¥—Ç–≤–æ—Ä–µ–Ω–Ω—è –∞—É–¥—ñ–æ –≤—ñ–¥ –º–æ–¥–µ–ª—ñ");
        isModelSpeaking = true;
      }
    } catch (e) {
      log("‚ùå –ü–æ–º–∏–ª–∫–∞ –≤—ñ–¥—Ç–≤–æ—Ä–µ–Ω–Ω—è:", e);
    }
  }

  // ---- Auto-fill WebSocket URL on page load ----
  window.addEventListener('DOMContentLoaded', () => {
    // Try to detect if running locally or need production URL
    const hostname = window.location.hostname;
    
    if (hostname === 'localhost' || hostname === '127.0.0.1') {
      // Local development
      $("wsUrl").value = "ws://localhost:8080/audio";
    } else {
      // Production - construct from current page URL
      const protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
      $("wsUrl").value = `${protocol}//${hostname}/audio`;
    }
    
    log("‚ÑπÔ∏è –°—Ç–æ—Ä—ñ–Ω–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–∞. –í–≤–µ–¥—ñ—Ç—å WebSocket URL —Ç–∞ –Ω–∞—Ç–∏—Å–Ω—ñ—Ç—å '–ü–æ—á–∞—Ç–∏ —Å–µ–∞–Ω—Å'");
  });

  // ---- Cleanup on page unload ----
  window.addEventListener('beforeunload', () => {
    stopMic();
    if (ws && ws.readyState === WebSocket.OPEN) {
      ws.close(1000, "Page unload");
    }
    if (audioCtx && audioCtx.state !== 'closed') {
      audioCtx.close();
    }
  });

})();
</script>
</body>
</html>

  

